Arguments:
batch_size: 128
valid_ratio: 0.5
augmentations: True
pretrained: True
num_epochs: 30
train_strats: ['fgsm']
visualise: False
epsilon_fgsm: 0.031
alpha_fgsm: 0.5
epsilon_pgd: 0.031
alpha_pgd: 0.0078
num_iter_pgd: 10
save_dir: /home/adeliev/uvadlc_practicals_2025/assignment3/part2/logs/fgsm_def
test_crossover_defense: False
Device: cuda
training_strategy: fgsm
Loading model
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /scratch-local/adeliev.17332732/17332732/torch_cache/hub/checkpoints/resnet18-f37072fd.pth
  0%|          | 0.00/44.7M [00:00<?, ?B/s] 63%|██████▎   | 28.2M/44.7M [00:00<00:00, 295MB/s]100%|██████████| 44.7M/44.7M [00:00<00:00, 293MB/s]
Loading data
  0%|          | 0.00/170M [00:00<?, ?B/s]  0%|          | 65.5k/170M [00:00<07:27, 381kB/s]  0%|          | 197k/170M [00:00<03:59, 711kB/s]   0%|          | 459k/170M [00:00<02:14, 1.26MB/s]  1%|          | 1.61M/170M [00:00<00:37, 4.51MB/s]  2%|▏         | 2.85M/170M [00:00<00:23, 6.99MB/s]  3%|▎         | 5.70M/170M [00:00<00:12, 13.6MB/s]  5%|▍         | 8.42M/170M [00:00<00:09, 17.6MB/s]  6%|▋         | 11.1M/170M [00:00<00:07, 20.3MB/s]  8%|▊         | 14.4M/170M [00:01<00:06, 24.1MB/s] 10%|▉         | 16.9M/170M [00:01<00:06, 24.3MB/s] 12%|█▏        | 20.4M/170M [00:01<00:05, 27.5MB/s] 14%|█▎        | 23.2M/170M [00:01<00:05, 27.7MB/s] 15%|█▌        | 26.3M/170M [00:01<00:05, 28.5MB/s] 17%|█▋        | 29.2M/170M [00:01<00:04, 28.7MB/s] 19%|█▉        | 32.3M/170M [00:01<00:04, 29.2MB/s] 21%|██        | 35.5M/170M [00:01<00:04, 30.0MB/s] 23%|██▎       | 38.6M/170M [00:01<00:04, 30.2MB/s] 25%|██▍       | 41.8M/170M [00:01<00:04, 30.9MB/s] 26%|██▋       | 45.0M/170M [00:02<00:04, 30.3MB/s] 29%|██▊       | 48.7M/170M [00:02<00:03, 30.9MB/s] 30%|███       | 51.8M/170M [00:02<00:03, 30.6MB/s] 32%|███▏      | 55.1M/170M [00:02<00:03, 31.2MB/s] 34%|███▍      | 58.2M/170M [00:02<00:03, 30.9MB/s] 36%|███▋      | 61.8M/170M [00:02<00:03, 32.4MB/s] 38%|███▊      | 65.1M/170M [00:02<00:03, 31.3MB/s] 41%|████      | 69.3M/170M [00:02<00:02, 34.4MB/s] 43%|████▎     | 72.7M/170M [00:02<00:03, 32.6MB/s] 45%|████▍     | 76.6M/170M [00:03<00:02, 34.4MB/s] 47%|████▋     | 80.6M/170M [00:03<00:02, 33.2MB/s] 50%|████▉     | 84.6M/170M [00:03<00:02, 34.9MB/s] 52%|█████▏    | 88.5M/170M [00:03<00:02, 33.6MB/s] 54%|█████▍    | 92.8M/170M [00:03<00:02, 36.0MB/s] 57%|█████▋    | 96.4M/170M [00:03<00:02, 33.7MB/s] 59%|█████▉    | 101M/170M [00:03<00:01, 36.0MB/s]  61%|██████    | 104M/170M [00:03<00:01, 34.0MB/s] 64%|██████▍   | 109M/170M [00:03<00:01, 36.6MB/s] 66%|██████▌   | 112M/170M [00:04<00:01, 34.2MB/s] 69%|██████▊   | 117M/170M [00:04<00:01, 36.7MB/s] 71%|███████   | 121M/170M [00:04<00:01, 34.3MB/s] 73%|███████▎  | 125M/170M [00:04<00:01, 36.8MB/s] 76%|███████▌  | 129M/170M [00:04<00:01, 34.5MB/s] 78%|███████▊  | 133M/170M [00:04<00:01, 33.7MB/s] 80%|████████  | 137M/170M [00:04<00:00, 35.8MB/s] 83%|████████▎ | 141M/170M [00:04<00:00, 34.1MB/s] 85%|████████▌ | 145M/170M [00:04<00:00, 36.1MB/s] 87%|████████▋ | 149M/170M [00:05<00:00, 34.0MB/s] 90%|████████▉ | 153M/170M [00:05<00:00, 36.1MB/s] 92%|█████████▏| 157M/170M [00:05<00:00, 34.0MB/s] 94%|█████████▍| 160M/170M [00:05<00:00, 35.3MB/s] 96%|█████████▋| 164M/170M [00:05<00:00, 34.0MB/s] 99%|█████████▉| 169M/170M [00:05<00:00, 36.2MB/s]100%|██████████| 170M/170M [00:05<00:00, 30.0MB/s]
Training model
Epoch 0/29
----------
train Loss: 1.9080 Acc: 0.4380
val Loss: 1.2573 Acc: 0.5383
Epoch 1/29
----------
train Loss: 1.5022 Acc: 0.5838
val Loss: 1.0685 Acc: 0.6080
Epoch 2/29
----------
train Loss: 1.3680 Acc: 0.6317
val Loss: 0.9860 Acc: 0.6395
Epoch 3/29
----------
train Loss: 1.2820 Acc: 0.6583
val Loss: 0.9219 Acc: 0.6658
Epoch 4/29
----------
train Loss: 1.2181 Acc: 0.6786
val Loss: 0.9073 Acc: 0.6816
Epoch 5/29
----------
train Loss: 1.1747 Acc: 0.6937
val Loss: 0.8257 Acc: 0.6916
Epoch 6/29
----------
train Loss: 1.1392 Acc: 0.7030
val Loss: 0.7899 Acc: 0.7000
Epoch 7/29
----------
train Loss: 1.1038 Acc: 0.7182
val Loss: 0.8092 Acc: 0.7049
Epoch 8/29
----------
train Loss: 1.0969 Acc: 0.7186
val Loss: 0.7906 Acc: 0.7057
Epoch 9/29
----------
train Loss: 1.0939 Acc: 0.7205
val Loss: 0.8010 Acc: 0.7084
Epoch 10/29
----------
train Loss: 1.0903 Acc: 0.7188
val Loss: 0.8117 Acc: 0.7072
Epoch 11/29
----------
train Loss: 1.0883 Acc: 0.7208
val Loss: 0.7738 Acc: 0.7113
Epoch 12/29
----------
train Loss: 1.0870 Acc: 0.7197
val Loss: 0.7918 Acc: 0.7121
Epoch 13/29
----------
train Loss: 1.0821 Acc: 0.7223
val Loss: 0.7750 Acc: 0.7119
Epoch 14/29
----------
train Loss: 1.0778 Acc: 0.7226
val Loss: 0.7626 Acc: 0.7123
Epoch 15/29
----------
train Loss: 1.0754 Acc: 0.7231
val Loss: 0.7752 Acc: 0.7139
Epoch 16/29
----------
train Loss: 1.0766 Acc: 0.7249
val Loss: 0.7688 Acc: 0.7150
Epoch 17/29
----------
train Loss: 1.0744 Acc: 0.7239
val Loss: 0.7978 Acc: 0.7139
Epoch 18/29
----------
train Loss: 1.0761 Acc: 0.7226
val Loss: 0.7877 Acc: 0.7094
Epoch 19/29
----------
train Loss: 1.0719 Acc: 0.7247
val Loss: 0.7978 Acc: 0.7129
Epoch 20/29
----------
train Loss: 1.0718 Acc: 0.7234
val Loss: 0.7824 Acc: 0.7143
Epoch 21/29
----------
train Loss: 1.0708 Acc: 0.7254
val Loss: 0.7824 Acc: 0.7125
Epoch 22/29
----------
train Loss: 1.0762 Acc: 0.7249
val Loss: 0.7780 Acc: 0.7107
Epoch 23/29
----------
train Loss: 1.0753 Acc: 0.7239
val Loss: 0.7803 Acc: 0.7131
Epoch 24/29
----------
train Loss: 1.0718 Acc: 0.7255
val Loss: 0.8081 Acc: 0.7113
Epoch 25/29
----------
train Loss: 1.0747 Acc: 0.7233
val Loss: 0.7934 Acc: 0.7123
Epoch 26/29
----------
train Loss: 1.0734 Acc: 0.7246
val Loss: 0.7840 Acc: 0.7123
Epoch 27/29
----------
train Loss: 1.0725 Acc: 0.7238
val Loss: 0.7921 Acc: 0.7098
Epoch 28/29
----------
train Loss: 1.0732 Acc: 0.7248
val Loss: 0.7755 Acc: 0.7152
Epoch 29/29
----------
train Loss: 1.0748 Acc: 0.7242
val Loss: 0.7760 Acc: 0.7154
Training complete in 4m 6s
Best val Acc: 0.715430
Testing model
Accuracy of the network on the test set: 72 %
Testing adversarial attacks
Attack fgsm, args: {'alpha': 0.5, 'epsilon': 0.031}
Test Accuracy = 2677 / 5000 = 0.5354
